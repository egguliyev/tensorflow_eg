import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

x = np.linspace(0,50,501)
y = np.sin(x)
plt.plot(x,y);

df = pd.DataFrame(data = y, index=x, columns=['Sine'])
test_percent = 0.1
test_point = np.round(len(df)*test_percent)
test_ind = int(len(df)-test_point)
train = df.iloc[:test_ind] #from begining up to index point

test = df.iloc[test_ind:] #test data from test_index all the way to end
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(train)
scaled_train = scaler.transform(train)
scaled_test = scaler.transform(test)
from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator 

length = 50 #it should be enough to have full cycle of data
batch_size = 1

generator = TimeseriesGenerator(scaled_train,scaled_train,length = length, batch_size=batch_size)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, SimpleRNN, LSTM


n_features = 1


# In[68]:


model = Sequential()


# In[70]:


model = Sequential()
model.add(SimpleRNN(50,input_shape=(length,n_features)))


# In[97]:


model = Sequential()
model.add(SimpleRNN(50,input_shape=(length,n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss = 'mse')


# In[98]:


model.summary()


# In[74]:


model.fit_generator(generator, epochs=5)


# In[75]:


lossess = pd.DataFrame(model.history.history)


# In[76]:


lossess.plot()


# In[77]:


first_eval_batch = scaled_train[-length:]


# In[78]:


first_eval_batch = first_eval_batch.reshape(1, length, n_features)


# In[79]:


model.predict(first_eval_batch)


test_prediction = []
first_eval_batch = scaled_train[-length:]
current_batch = first_eval_batch.reshape(1, length, n_features)

for i in range(len(test)):
    current_pred = model.predict(current_batch)[0]
    test_prediction.append(current_pred)
    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)


# In[87]:


true_predictions = scaler.inverse_transform(test_prediction)

test['Predictions'] = true_predictions

test.plot(figsize=(12,8))


from tensorflow.keras.callbacks import EarlyStopping


early_stop = EarlyStopping(monitor='val_loss', patience=2)


length = 49
generator = TimeseriesGenerator(scaled_train,scaled_train, length=length, batch_size=1)
validation_generator = TimeseriesGenerator(scaled_test, scaled_test, length=length,batch_size=1)


model = Sequential()
model.add(LSTM(50,input_shape=(length,n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss = 'mse')

model.fit(generator,epochs=20,
          validation_data=validation_generator,
          callbacks = [early_stop])

test_prediction = []
first_eval_batch = scaled_train[-length:]
current_batch = first_eval_batch.reshape(1, length, n_features)

for i in range(len(test)):
    current_pred = model.predict(current_batch)[0]
    test_prediction.append(current_pred)
    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)

true_predictions = scaler.inverse_transform(test_prediction)
test['LSTM Predictions'] = true_predictions
test.plot(figsize=(12,8))

df.plot()

full_scaler = MinMaxScaler()
scaled_full_data = full_scaler.fit_transform(df)


generator = TimeseriesGenerator(scaled_full_data,
                               scaled_full_data,
                               length=length,
                               batch_size = 1)

model = Sequential()
model.add(LSTM(50,input_shape=(length,n_features)))
model.add(Dense(1))
model.compile(optimizer='adam', loss = 'mse')


model.fit(generator,epochs=5,
          validation_data=validation_generator,
          callbacks = [early_stop])

forecast = []
first_eval_batch = scaled_train[-length:]
current_batch = first_eval_batch.reshape(1, length, n_features)

for i in range(250):
    current_pred = model.predict(current_batch)[0]
    forecast.append(current_pred)
    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)

forecast = scaler.inverse_transform(forecast)

forecast_index = np.arange(45.1,70.1,step=0.1)
plt.plot(df.index,df['Sine'])
plt.plot(forecast_index,forecast)

